{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "from tfs.dataset import Mnist\n",
    "dataset = Mnist()\n",
    "#dataset.transpose([0,2,3,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'prob:0' shape=(?, 10) dtype=float32>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tfs.network import CustomNetwork\n",
    "class MyNet(CustomNetwork):\n",
    "    def setup(self):\n",
    "        self.default_data_format='NHWC'\n",
    "        self.default_in_shape = [None,28,28,1]\n",
    "        (self.net_def\n",
    "         .conv2d([5,5],64, [1,1], padding='SAME', name='conv1') # (?, 64, 32, 32)\n",
    "         .maxpool([3, 3], [2,2] , padding='SAME', name='pool1') # (?, 64, 16, 16)\n",
    "         .lrn(2, 2e-05, 0.75, name='norm1')\n",
    "         .conv2d([5,5],32, [1,1], padding='SAME', name='conv2') #(?, 32, 16, 16)\n",
    "         .maxpool([3, 3], [2, 2], padding='SAME', name='pool2') # (?, 32, 8, 8)\n",
    "         .lrn(2, 2e-05, 0.75, name='norm2')\n",
    "         .conv2d([3, 3], 16, [1, 1], name='conv3') # (1, 16, 8, 8)\n",
    "         .conv2d([3, 3], 8, [1, 1], name='conv5') # (1, 8, 8, 8)\n",
    "         .maxpool([3, 3], [2, 2], padding='SAME', name='pool5') # (1, 6, 6, 256)\n",
    "         .fc(64, name='fc6')\n",
    "         .fc(64, name='fc7')\n",
    "         .fc(10, activation=False, name='fc8')\n",
    "         .softmax(name='prob'))\n",
    "        self.loss_input_layer_name = 'fc8'\n",
    "\n",
    "net = MyNet()\n",
    "net.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'prob:0' shape=(?, 10) dtype=float32>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tfs.models import LeNet\n",
    "net=LeNet()\n",
    "net.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1                       (?, 28, 28, 1) -> (?, 24, 24, 20)     \n",
      "pool1                      (?, 24, 24, 20) -> (?, 12, 12, 20)     \n",
      "conv2                      (?, 12, 12, 20) -> (?, 8, 8, 50)       \n",
      "pool2                        (?, 8, 8, 50) -> (?, 4, 4, 50)       \n",
      "ip1                          (?, 4, 4, 50) -> (?, 500)            \n",
      "ip2                               (?, 500) -> (?, 10)             \n",
      "prob                               (?, 10) -> (?, 10)             \n"
     ]
    }
   ],
   "source": [
    "net.print_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:conv1     \tType:Conv2d(knum=20,ksize=[5, 5],strides=[1, 1],padding=VALID,activation=None)\n",
      "Name:pool1     \tType:MaxPool(ksize=[2, 2],strides=[2, 2])\n",
      "Name:conv2     \tType:Conv2d(knum=50,ksize=[5, 5],strides=[1, 1],padding=VALID,activation=relu)\n",
      "Name:pool2     \tType:MaxPool(ksize=[2, 2],strides=[2, 2])\n",
      "Name:ip1       \tType:FullyConnect(outdim=500,activation=relu)\n",
      "Name:ip2       \tType:FullyConnect(outdim=10,activation=None)\n",
      "Name:prob      \tType:Softmax()\n",
      "---OPT---\n",
      "AdamOptimizer\n",
      "-----param-----\n",
      "learning_rate=ExponentialDecay_LR(decay_steps=10000,init_value=0.001,decay_rate=0.96),print_names=['learning_rate']\n",
      "---------------\n",
      "---REG---\n",
      "\n",
      "---LOSS--\n",
      "CrossEntropyByLogitLabel (ip2)\n",
      "-----param-----\n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "print net\n",
    "print '---OPT---'\n",
    "print net.optimizer\n",
    "print '---REG---'\n",
    "print net.regularizer\n",
    "print '---LOSS--'\n",
    "print net.losser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.001000,step 10. loss 5.883820, score:0.485600\n",
      "lr: 0.001000,step 20. loss 0.884913, score:0.693000\n",
      "lr: 0.001000,step 30. loss 0.498188, score:0.825500\n",
      "lr: 0.001000,step 40. loss 0.410167, score:0.883100\n",
      "lr: 0.001000,step 50. loss 0.238482, score:0.909000\n",
      "lr: 0.001000,step 60. loss 0.204807, score:0.915900\n",
      "lr: 0.001000,step 70. loss 0.323365, score:0.922000\n",
      "lr: 0.001000,step 80. loss 0.267333, score:0.935600\n",
      "lr: 0.001000,step 90. loss 0.156741, score:0.945000\n",
      "lr: 0.001000,step 100. loss 0.105406, score:0.946900\n",
      "lr: 0.001000,step 110. loss 0.082555, score:0.949300\n",
      "lr: 0.001000,step 120. loss 0.163603, score:0.953900\n",
      "lr: 0.001000,step 130. loss 0.205548, score:0.953500\n",
      "lr: 0.001000,step 140. loss 0.081753, score:0.954100\n",
      "lr: 0.001000,step 150. loss 0.126920, score:0.957400\n",
      "lr: 0.001000,step 160. loss 0.129416, score:0.960100\n",
      "lr: 0.001000,step 170. loss 0.071119, score:0.963100\n",
      "lr: 0.001000,step 180. loss 0.127172, score:0.963500\n",
      "lr: 0.001000,step 190. loss 0.131317, score:0.961700\n",
      "lr: 0.001000,step 200. loss 0.105080, score:0.957000\n",
      "lr: 0.001000,step 210. loss 0.114409, score:0.962700\n",
      "lr: 0.001000,step 220. loss 0.133494, score:0.958200\n",
      "lr: 0.001000,step 230. loss 0.135159, score:0.963100\n",
      "lr: 0.001000,step 240. loss 0.125408, score:0.967000\n",
      "lr: 0.001000,step 250. loss 0.146648, score:0.969100\n",
      "lr: 0.001000,step 260. loss 0.113136, score:0.966800\n",
      "lr: 0.001000,step 270. loss 0.110646, score:0.968800\n",
      "lr: 0.001000,step 280. loss 0.097053, score:0.965600\n",
      "lr: 0.001000,step 290. loss 0.115332, score:0.969100\n",
      "lr: 0.001000,step 300. loss 0.152582, score:0.968800\n",
      "lr: 0.001000,step 310. loss 0.036679, score:0.970500\n",
      "lr: 0.001000,step 320. loss 0.123302, score:0.972400\n",
      "lr: 0.001000,step 330. loss 0.080348, score:0.967700\n",
      "lr: 0.001000,step 340. loss 0.049094, score:0.973000\n",
      "lr: 0.001000,step 350. loss 0.021700, score:0.976100\n",
      "lr: 0.001000,step 360. loss 0.039561, score:0.976200\n",
      "lr: 0.001000,step 370. loss 0.037269, score:0.972600\n",
      "lr: 0.001000,step 380. loss 0.027559, score:0.973900\n",
      "lr: 0.001000,step 390. loss 0.077754, score:0.972800\n",
      "lr: 0.001000,step 400. loss 0.087450, score:0.970400\n",
      "lr: 0.001000,step 410. loss 0.066010, score:0.970000\n",
      "lr: 0.001000,step 420. loss 0.059010, score:0.972900\n",
      "lr: 0.001000,step 430. loss 0.034543, score:0.974200\n",
      "lr: 0.001000,step 440. loss 0.116618, score:0.975000\n",
      "lr: 0.001000,step 450. loss 0.042091, score:0.976300\n",
      "lr: 0.001000,step 460. loss 0.104666, score:0.974800\n",
      "lr: 0.001000,step 470. loss 0.019342, score:0.973900\n",
      "lr: 0.001000,step 480. loss 0.061094, score:0.975100\n",
      "lr: 0.001000,step 490. loss 0.036007, score:0.976600\n",
      "lr: 0.001000,step 500. loss 0.047143, score:0.977100\n",
      "lr: 0.001000,step 510. loss 0.043690, score:0.974600\n",
      "lr: 0.001000,step 520. loss 0.028133, score:0.976800\n",
      "lr: 0.001000,step 530. loss 0.149913, score:0.977400\n",
      "lr: 0.001000,step 540. loss 0.064058, score:0.976500\n",
      "lr: 0.001000,step 550. loss 0.089989, score:0.977000\n",
      "lr: 0.001000,step 560. loss 0.049366, score:0.973500\n",
      "lr: 0.001000,step 570. loss 0.021600, score:0.973900\n",
      "lr: 0.001000,step 580. loss 0.036496, score:0.975600\n",
      "lr: 0.001000,step 590. loss 0.050474, score:0.976500\n",
      "lr: 0.001000,step 600. loss 0.118216, score:0.977200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tfs.models.lenet.LeNet at 0x7ffba0e4f150>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.fit(dataset,batch_size=200,n_epoch=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.train.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
