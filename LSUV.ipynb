{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# default initialize with Xavier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 10. loss 3.655696, score:0.546600\n",
      "step 20. loss 0.723743, score:0.749500\n",
      "step 30. loss 0.664948, score:0.846000\n",
      "step 40. loss 0.392544, score:0.887300\n",
      "step 50. loss 0.403155, score:0.911100\n",
      "step 60. loss 0.329736, score:0.925000\n",
      "step 70. loss 0.295869, score:0.935600\n",
      "step 80. loss 0.245136, score:0.944400\n",
      "step 90. loss 0.154759, score:0.946300\n",
      "step 100. loss 0.234490, score:0.949400\n",
      "step 110. loss 0.123667, score:0.953800\n",
      "step 120. loss 0.236989, score:0.955100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tfs.models.lenet.LeNet at 0x7f48bd45c510>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tfs.models import LeNet\n",
    "net = LeNet()\n",
    "from tfs.dataset import Mnist\n",
    "dataset = Mnist()\n",
    "net.build()\n",
    "net.fit(dataset,batchsize,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSUV initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfs.core.initializer import Initializer,InitType\n",
    "from tfs.core.layer import *\n",
    "import numpy as np\n",
    "\n",
    "def svd_orthonormal(shape):\n",
    "    if len(shape) < 2:\n",
    "        raise RuntimeError(\"Only shapes of length 2 or more are supported.\")\n",
    "    flat_shape = (shape[0], np.prod(shape[1:]))\n",
    "    a = np.random.standard_normal(flat_shape)\n",
    "    u, _, v = np.linalg.svd(a, full_matrices=False)\n",
    "    q = u if u.shape == flat_shape else v\n",
    "    q = q.reshape(shape)\n",
    "    return q\n",
    "\n",
    "# this initializer would also change the weight of current net.\n",
    "class LSUV(Initializer):\n",
    "    ret_type = InitType.values\n",
    "    available_node_type = [Conv2d, FullyConnect]\n",
    "    def __init__(\n",
    "        self,\n",
    "        net,\n",
    "        batchX,\n",
    "        print_names=[]\n",
    "    ):\n",
    "        vs = locals()\n",
    "        net = vs['net']\n",
    "        del vs['self']\n",
    "        del vs['net']\n",
    "        super(LSUV,self).__init__(net,**vs)\n",
    "        \n",
    "    def _build_init_table(self):\n",
    "        tbl = {}\n",
    "        margin = 0.1\n",
    "        max_iter = 10\n",
    "        for n in self.net.net_def:\n",
    "            print(type(n).__name__)\n",
    "            if type(n) not in self.available_node_type:\n",
    "                continue\n",
    "            my_dict = {}\n",
    "            \n",
    "            name = 'weights'\n",
    "            v = n.variables[name]\n",
    "            defaultInitOp = n.initializers[name]\n",
    "            val = defaultInitOp(v.get_shape().as_list(),v.dtype.base_dtype)\n",
    "            myval = svd_orthonormal(val.shape)\n",
    "            my_dict[name] = myval\n",
    "            \n",
    "            name = 'biases'\n",
    "            v = n.variables[name]\n",
    "            defaultInitOp = n.initializers[name]\n",
    "            val = defaultInitOp(v.get_shape().as_list(),v.dtype.base_dtype)\n",
    "            myval = val\n",
    "            my_dict[name] = myval\n",
    "            \n",
    "            n.set_weights(my_dict)\n",
    "            \n",
    "            acts1 = self.net.eval_node(n,self.param.batchX)\n",
    "            var1=np.var(acts1)\n",
    "            iter1=0\n",
    "            needed_variance = 1.0\n",
    "            print(var1)\n",
    "            \n",
    "            while (abs(needed_variance - var1) > margin):\n",
    "                weights = self.net.run(n.variables['weights'])\n",
    "                biases = self.net.run(n.variables['biases'])\n",
    "                weights /= np.sqrt(var1)/np.sqrt(needed_variance)\n",
    "                w_all_new = {'weights':weights,\n",
    "                             'biases':biases}\n",
    "                n.set_weights(w_all_new)\n",
    "                acts1=self.net.eval_node(n,self.param.batchX)\n",
    "                var1=np.var(acts1)\n",
    "                iter1+=1\n",
    "                print(var1)\n",
    "                if iter1 > max_iter:\n",
    "                    break            \n",
    "\n",
    "        # it is initialized during the loop, so we can return a nil tbl\n",
    "        return tbl\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfs.models import LeNet\n",
    "net = LeNet()\n",
    "from tfs.dataset import Mnist\n",
    "dataset = Mnist()\n",
    "batchX,batchY = dataset.train.next_batch(batchsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.initializer = LSUV(net,batchX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d\n",
      "2481.81\n",
      "1.0\n",
      "MaxPool\n",
      "Conv2d\n",
      "0.0820143\n",
      "0.856374\n",
      "0.994984\n",
      "MaxPool\n",
      "FullyConnect\n",
      "1.10542\n",
      "1.00325\n",
      "FullyConnect\n",
      "0.916689\n",
      "Softmax\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'prob:0' shape=(?, 10) dtype=float32>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.build() # the number represent the variances that we adjust."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 10. loss 0.636787, score:0.794900\n",
      "step 20. loss 0.304964, score:0.864200\n",
      "step 30. loss 0.299373, score:0.933700\n",
      "step 40. loss 0.135905, score:0.951200\n",
      "step 50. loss 0.202405, score:0.959800\n",
      "step 60. loss 0.127498, score:0.957700\n",
      "step 70. loss 0.143419, score:0.966200\n",
      "step 80. loss 0.098482, score:0.967600\n",
      "step 90. loss 0.090081, score:0.971400\n",
      "step 100. loss 0.140789, score:0.975000\n",
      "step 110. loss 0.081888, score:0.975900\n",
      "step 120. loss 0.149892, score:0.976600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tfs.models.lenet.LeNet at 0x7f4881ab78d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.fit(dataset,batchsize,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
